{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %load /home/biswadip/autoreload_jn.py\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load sentiment\\ analysis-attention.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# In[2]:\n",
    "import os\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# In[53]:\n",
    "\n",
    "\n",
    "from models.text import CustomTokenizer\n",
    "from models.model import word_list, max_sentences, maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CustomTokenizer(word_list = word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_s = 32\n",
    "\n",
    "path = \"negativeReviews/\"\n",
    "neg_reviews = []\n",
    "for f in os.listdir(path):\n",
    "    file = os.path.join(path, f)\n",
    "    with open(file, \"r\") as fl:\n",
    "        neg_reviews.append(fl.read())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"positiveReviews//\"\n",
    "pos_reviews = []\n",
    "for f in os.listdir(path):\n",
    "    file = os.path.join(path, f)\n",
    "    with open(file, \"r\") as fl:\n",
    "        pos_reviews.append(fl.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape (25000, 2)\n",
      "Class Distribution 1    12500\n",
      "0    12500\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(\n",
    "    {\"text\":neg_reviews, \"sentiment\":0}\n",
    ").append(pd.DataFrame(\n",
    "    {\"text\":pos_reviews, \"sentiment\":1}\n",
    "))\n",
    "\n",
    "print(\"Data Shape {}\".format(data.shape))\n",
    "# data.to_csv(\"tagged_data.csv\")\n",
    "print(\"Class Distribution {}\".format(\n",
    "    data.sentiment.value_counts())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()\n",
    "\n",
    "data = data.filter([\"text\",\"sentiment\"])\n",
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "import tensorflow as tf\n",
    "\n",
    "inp = tokenizer.doc_to_sequences(data.text.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for doc in inp:\n",
    "    inputs.append(\n",
    "        tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            doc, padding=\"post\", value=0, maxlen=maxlen, dtype=None\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((len(inputs),max_sentences,maxlen))\n",
    "\n",
    "for row,x in zip(a, inputs):\n",
    "    row[:len(x)] = x[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "\n",
    "from models.model import get_model, ModelCheckpoint, max_sentences, maxlen\n",
    "from models.model import HierarchicalAttentionLayer, SequenceAttentionLayer, AdditiveAttention\n",
    "from models.data import Sequence_generator\n",
    "# from models.tuner import tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    \"model/attention-wh_100_sh_600-01-0.79.h5\",\n",
    "    custom_objects={\"HierarchicalAttentionLayer\": HierarchicalAttentionLayer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sorry, I just didn\\'t find the subject matter as compelling as the filmmaker did. The robot guy and the mole rat guy were pretty interesting, although Morris didn\\'t really tell us much about them. The other two subjects were a bore. And the supposed \"connections\" between them didn\\'t hold up.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13388208, 0.8661179 ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(a[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hirer_layer = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_layer = hirer_layer.sentence_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed, lstm, attention = sentence_layer.embed, sentence_layer.lstm, sentence_layer.attention_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_layer.embedding_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh= tf.reshape(\n",
    "        embed(a[:2]), \n",
    "        shape = (-1 ,maxlen ,sentence_layer.embedding_len)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 80, 50])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 50)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen, max_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_reshaped = tf.reshape(\n",
    "        embed(a[:2]), \n",
    "        shape = (-1 ,maxlen ,sentence_layer.embedding_len)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tf.reshape(\n",
    "    embed(a[:2])._keras_mask,\n",
    "    shape = (-1, maxlen)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_output = lstm(\n",
    "    embed_reshaped, mask=mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mask = lstm_output._keras_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention([lstm_output, lstm_output], mask = [lstm_mask, lstm_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "atten_scores = attention.get_attention_scores([lstm_output, lstm_output], mask = [lstm_mask, lstm_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'most'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word[a[:2][0][2][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a[:2][0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(80, 80), dtype=int32, numpy=\n",
       "array([[12,  5,  6, ..., 77, 78, 79],\n",
       "       [12,  5,  6, ..., 77, 78, 79],\n",
       "       [12,  5,  6, ..., 77, 78, 79],\n",
       "       ...,\n",
       "       [12,  5,  6, ..., 77, 78, 79],\n",
       "       [12,  5,  6, ..., 77, 78, 79],\n",
       "       [12,  5,  6, ..., 77, 78, 79]], dtype=int32)>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argsort(atten_scores[0], direction=\"DESCENDING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atten_scores[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atten_scores[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In my humble opinion, this movie did not receive the recognition it deserved. Robert Redford lives near me here in Provo, Utah, at Sundance. I enjoy most of his work, and this was my favorite. I\\'m sorry that more people didn\\'t appreciate it. My grandmother was an avid reader and read the book years before it came out on the big screen. She gave it to me to read after we had seen the movie together. The movie and book hit an emotional spot within my heart, and I was weepy for several days after seeing the movie. Sometimes love isn\\'t enough to keep our loved ones from hurting themselves. We see this in our own family relationships, yet our love and our families and their stories endure throughout generations of time. The cinematography was perfect and breathtaking -- I was awed by its beauty and how well it brought to life the words of the author of the book, Norman Maclean, \"But when I am alone in the half light of the canyon, all existence seems to fade to a being with my soul, and memories. And the sounds of the Big Black Foot River, and a four count rhythm, and the hope that a fish will rise. Eventually, all things merge into one, and a river runs through it. The river was cut by the world\\'s great flood and runs over rocks from the basement of time. On some of the rocks are timeless raindrops. Under the rocks are the words, and some of the words are theirs. I am haunted by waters.\" These words, taken from the book and spoken at the end of the movie (by Robert Redford who is narrating as Norman Maclean), are basically scripture, in my opinion. Any possible flaws the movie may have are overshadowed by the beauty and grace of the story and the cinematography. It was beautiful!'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python venv3",
   "language": "python",
   "name": "envname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
