from .text import CustomTokenizer as Tokenizer

from .word_vector import word_list
from .model import maxlen, max_sentences